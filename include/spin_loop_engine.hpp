#pragma once

#include "common_types.hpp"
#include <atomic>
#include <thread>
#include <cmath>

#if defined(__linux__)
    #include <pthread.h>
    #include <sched.h>
#elif defined(__APPLE__)
    #include <pthread.h>
    #include <mach/thread_policy.h>
    #include <mach/thread_act.h>
#endif

namespace hft {
namespace spin_loop {

// ====
// CPU Affinity and Priority Control
// ====

/**
 * Pin thread to specific CPU core
 */
inline bool pin_to_cpu(int cpu_id) {
#if defined(__linux__)
    cpu_set_t cpuset;
    CPU_ZERO(&cpuset);
    CPU_SET(cpu_id, &cpuset);
    
    pthread_t thread = pthread_self();
    int result = pthread_setaffinity_np(thread, sizeof(cpu_set_t), &cpuset);
    return (result == 0);
    
#elif defined(__APPLE__)
    // macOS: Use thread_policy_set
    thread_affinity_policy_data_t policy = { cpu_id };
    thread_port_t mach_thread = pthread_mach_thread_np(pthread_self());
    
    kern_return_t result = thread_policy_set(
        mach_thread,
        THREAD_AFFINITY_POLICY,
        (thread_policy_t)&policy,
        THREAD_AFFINITY_POLICY_COUNT
    );
    return (result == KERN_SUCCESS);
    
#else
    // Not supported on this platform
    return false;
#endif
}

/**
 * Set thread to real-time priority
 * 
 * Prevents OS from preempting the thread for other processes
 */
inline bool set_realtime_priority() {
#if defined(__linux__)
    struct sched_param param;
    param.sched_priority = sched_get_priority_max(SCHED_FIFO);
    
    int result = pthread_setschedparam(pthread_self(), SCHED_FIFO, &param);
    return (result == 0);
    
#elif defined(__APPLE__)
    // macOS: Use thread_policy_set with THREAD_TIME_CONSTRAINT_POLICY
    thread_time_constraint_policy_data_t policy;
    policy.period = 0;
    policy.computation = 1000000;  // 1ms
    policy.constraint = 2000000;   // 2ms
    policy.preemptible = 0;        // Non-preemptible
    
    thread_port_t mach_thread = pthread_mach_thread_np(pthread_self());
    kern_return_t result = thread_policy_set(
        mach_thread,
        THREAD_TIME_CONSTRAINT_POLICY,
        (thread_policy_t)&policy,
        THREAD_TIME_CONSTRAINT_POLICY_COUNT
    );
    return (result == KERN_SUCCESS);
    
#else
    return false;
#endif
}

// ====
// Math Look-Up Tables (LUTs)
// ====

/**
 * Pre-computed natural logarithm table
 * 
 * Range: [0.1, 10.0]
 * Precision: 0.0001 steps = 100,000 entries
 */
class LnLookupTable {
public:
    static constexpr double MIN_X = 0.01;
    static constexpr double MAX_X = 100.0;
    static constexpr double STEP = 0.0001;
    static constexpr size_t TABLE_SIZE = static_cast<size_t>((MAX_X - MIN_X) / STEP) + 1;
    
    LnLookupTable() {
        // Pre-compute ln values at compile time (or first use)
        for (size_t i = 0; i < TABLE_SIZE; i++) {
            double x = MIN_X + i * STEP;
            table_[i] = std::log(x);
        }
    }
    
    /**
     * Fast ln lookup
     */
    inline double lookup(double x) const {
        // Clamp to valid range
        if (x < MIN_X) return std::log(MIN_X);
        if (x > MAX_X) return std::log(MAX_X);
        
        // Calculate table index
        size_t idx = static_cast<size_t>((x - MIN_X) / STEP);
        if (idx >= TABLE_SIZE) idx = TABLE_SIZE - 1;
        
        return table_[idx];
    }
    
    /**
     * Interpolated ln lookup (higher accuracy, ~8-10ns)
     */
    inline double lookup_interp(double x) const {
        if (x < MIN_X) return std::log(MIN_X);
        if (x > MAX_X) return std::log(MAX_X);
        
        double fractional_idx = (x - MIN_X) / STEP;
        size_t idx = static_cast<size_t>(fractional_idx);
        if (idx >= TABLE_SIZE - 1) return table_[TABLE_SIZE - 1];
        
        // Linear interpolation
        double frac = fractional_idx - idx;
        return table_[idx] * (1.0 - frac) + table_[idx + 1] * frac;
    }

private:
    alignas(64) std::array<double, TABLE_SIZE> table_;
};

/**
 * Pre-computed exponential table
 * 
 * Range: [-10.0, 10.0]
 * Precision: 0.001 steps = 20,000 entries
 */
class ExpLookupTable {
public:
    static constexpr double MIN_X = -10.0;
    static constexpr double MAX_X = 10.0;
    static constexpr double STEP = 0.001;
    static constexpr size_t TABLE_SIZE = static_cast<size_t>((MAX_X - MIN_X) / STEP) + 1;
    
    ExpLookupTable() {
        for (size_t i = 0; i < TABLE_SIZE; i++) {
            double x = MIN_X + i * STEP;
            table_[i] = std::exp(x);
        }
    }
    
    inline double lookup(double x) const {
        if (x < MIN_X) return std::exp(MIN_X);
        if (x > MAX_X) return std::exp(MAX_X);
        
        size_t idx = static_cast<size_t>((x - MIN_X) / STEP);
        if (idx >= TABLE_SIZE) idx = TABLE_SIZE - 1;
        
        return table_[idx];
    }
    
    inline double lookup_interp(double x) const {
        if (x < MIN_X) return std::exp(MIN_X);
        if (x > MAX_X) return std::exp(MAX_X);
        
        double fractional_idx = (x - MIN_X) / STEP;
        size_t idx = static_cast<size_t>(fractional_idx);
        if (idx >= TABLE_SIZE - 1) return table_[TABLE_SIZE - 1];
        
        double frac = fractional_idx - idx;
        return table_[idx] * (1.0 - frac) + table_[idx + 1] * frac;
    }

private:
    alignas(64) std::array<double, TABLE_SIZE> table_;
};

/**
 * Pre-computed square root table
 * 
 * Range: [0.0, 1000.0]
 * Precision: 0.01 steps = 100,000 entries
 */
class SqrtLookupTable {
public:
    static constexpr double MIN_X = 0.0;
    static constexpr double MAX_X = 1000.0;
    static constexpr double STEP = 0.01;
    static constexpr size_t TABLE_SIZE = static_cast<size_t>((MAX_X - MIN_X) / STEP) + 1;
    
    SqrtLookupTable() {
        for (size_t i = 0; i < TABLE_SIZE; i++) {
            double x = MIN_X + i * STEP;
            table_[i] = std::sqrt(x);
        }
    }
    
    inline double lookup(double x) const {
        if (x < MIN_X) return 0.0;
        if (x > MAX_X) return std::sqrt(MAX_X);
        
        size_t idx = static_cast<size_t>((x - MIN_X) / STEP);
        if (idx >= TABLE_SIZE) idx = TABLE_SIZE - 1;
        
        return table_[idx];
    }
    
    inline double lookup_interp(double x) const {
        if (x < MIN_X) return 0.0;
        if (x > MAX_X) return std::sqrt(MAX_X);
        
        double fractional_idx = (x - MIN_X) / STEP;
        size_t idx = static_cast<size_t>(fractional_idx);
        if (idx >= TABLE_SIZE - 1) return table_[TABLE_SIZE - 1];
        
        double frac = fractional_idx - idx;
        return table_[idx] * (1.0 - frac) + table_[idx + 1] * frac;
    }

private:
    alignas(64) std::array<double, TABLE_SIZE> table_;
};

/**
 * Global LUT instances (singleton pattern)
 */
inline LnLookupTable& get_ln_lut() {
    static LnLookupTable lut;
    return lut;
}

inline ExpLookupTable& get_exp_lut() {
    static ExpLookupTable lut;
    return lut;
}

inline SqrtLookupTable& get_sqrt_lut() {
    static SqrtLookupTable lut;
    return lut;
}

// Fast math functions using LUTs
inline double fast_ln(double x) { return get_ln_lut().lookup(x); }
inline double fast_exp(double x) { return get_exp_lut().lookup(x); }
inline double fast_sqrt(double x) { return get_sqrt_lut().lookup(x); }

// Interpolated versions (slightly slower but more accurate)
inline double fast_ln_interp(double x) { return get_ln_lut().lookup_interp(x); }
inline double fast_exp_interp(double x) { return get_exp_lut().lookup_interp(x); }
inline double fast_sqrt_interp(double x) { return get_sqrt_lut().lookup_interp(x); }

// ====
// Spin-Loop Engine
// ====

/**
 * Single-threaded busy-wait engine for critical path processing
 */
template<typename WorkFunc>
class SpinLoopEngine {
public:
    SpinLoopEngine(int cpu_id = 0) 
        : running_(false), 
          work_available_(false),
          cpu_id_(cpu_id) {}
    
    /**
     * Start the spin loop on dedicated thread
     */
    void start(WorkFunc work_func) {
        running_.store(true, std::memory_order_release);
        
        thread_ = std::thread([this, work_func]() {
            // Pin to CPU core
            if (!pin_to_cpu(cpu_id_)) {
                // Warning: Could not pin to CPU
            }
            
            // Set real-time priority
            if (!set_realtime_priority()) {
                // Warning: Could not set real-time priority
            }
            
            // Busy-wait spin loop (100% CPU usage)
            while (running_.load(std::memory_order_acquire)) {
                // Check if work is available (atomic, very fast)
                if (work_available_.load(std::memory_order_acquire)) {
                    // Execute work immediately
                    work_func();
                    
                    // Mark work as done
                    work_available_.store(false, std::memory_order_release);
                }
                
                // Optional: Add pause instruction to reduce power/heat
                // (adds ~1-2ns but saves CPU power)
                #if defined(__x86_64__) || defined(_M_X64)
                    _mm_pause();  // x86 PAUSE instruction
                #elif defined(__aarch64__) || defined(_M_ARM64)
                    __asm__ __volatile__("yield");  // ARM YIELD instruction
                #endif
            }
        });
    }
    
    /**
     * Signal work is available
     */
    inline void signal_work() {
        work_available_.store(true, std::memory_order_release);
    }
    
    /**
     * Stop the spin loop
     */
    void stop() {
        running_.store(false, std::memory_order_release);
        if (thread_.joinable()) {
            thread_.join();
        }
    }
    
    ~SpinLoopEngine() {
        stop();
    }

private:
    std::atomic<bool> running_;
    std::atomic<bool> work_available_;
    std::thread thread_;
    int cpu_id_;
};

} // namespace spin_loop
} // namespace hft
